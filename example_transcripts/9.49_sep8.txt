
Ra√∫l Mojica
00:00:15
Yeah, I think that's it.
user avatar
Ila Fiete
00:00:19
Fantastic write as many gardeners here though.
user avatar
Tho Tran
00:00:26
High up though. I'm the TA
00:00:28
Of this class. I'm an image students concentrating and AI. And besides, for a I used to do karate. But now, everything's closed so I don't do it very much. I have my cat with me have two cats. So, which are like, like what
user avatar
Ila Fiete
00:00:49
You showed us only one last time someone time sometime. You'll have to show us the second
user avatar
Tho Tran
00:00:52
Yeah, the other one is more shy so
00:00:57
Carrie.
user avatar
Yizhi (Cherry) Wang
00:00:59
Hi I'm Sherry. I'm over quarantine. I think I've always loved to cook.
00:01:04
And most recently, I've been trying to perfect this Peruvian drink that I tried one time on this coach each other and it's like boiled from purple corn with like cinnamon sticks. Apples, pineapples clothes.
00:01:18
And it's really sweet. And it's really good. So I've been trying to perfect that and I'm also trying to do some more theater. And I actually just auditioned for a play yesterday, which I hope I can get to do this semester.
user avatar
Ila Fiete
00:01:33
Oh, I hope you get the part you
00:01:38
wiki.
00:01:38
Is that how you say your name.
user avatar
Joachim J Kennedy
00:01:41
Joe
00:01:45
Joe
00:01:47
I haven't picked up any new car team hobbies. I've just been doing much more of the things that he has to do with our reading and running so
user avatar
Ila Fiete
00:01:59
Lately,
user avatar
Joachim J Kennedy
00:02:01
What have you
user avatar
Ila Fiete
00:02:02
Done lately.
user avatar
Joachim J Kennedy
00:02:03
I I read the bell jar, which really surprised me. I thought it was
00:02:10
A lot of the autobiography of Malcolm X, yeah.
00:02:16
Currently reading Gone Girl.
user avatar
Ila Fiete
00:02:18
Oh, nice. Stephen
user avatar
Steven Meisler
00:02:24
Stephen. I'm a grad student. I've been
00:02:29
composing music
00:02:32
Playing a I've a group of a couple of students in my program. And then I also tried my hand at making ginger beer, but it has not gone well
user avatar
Ila Fiete
00:02:43
Like the carbonated variety
00:02:47
Wow. Yeah.
00:02:54
What's the hard part.
00:02:56
It's this is natural carbonation or this is carbon dioxide. This card like you inject carbon dioxide, which is natural fermentation
user avatar
Steven Meisler
00:03:03
Natural it the skin of ginger has some nice to it. So you have to cultivate a youth culture, just using ginger skins.
user avatar
Minyoung Kim
00:03:16
I am maybe I'm
00:03:17
I'm I used to be doing exercise a lot of outdoor sports but then over to parenting. I couldn't do it. So I picked it up to cooking as many others. And then I started gaining a lot of weights. So I stopped cooking.
00:03:34
And recently I picked up my eBook Reader again. And I've been reading a lot like especially like a non academic thing like a novel and say fi thing and it's helping because I'm started, I started to lose the weights again.
user avatar
Ila Fiete
00:03:54
Leanne.
user avatar
Liane Z Xu
00:03:56
Um, yeah.
00:03:57
Hi I'm Leanne over quarantine.
00:04:01
I i guess i picked up handstands again. So I did gymnastics. When I was like really little, and hadn't done it for a while. So I'm just kind of getting back into it.
user avatar
Ila Fiete
00:04:16
Do you have a gym that you go to, or
00:04:18
Is it just outdoors.
user avatar
Liane Z Xu
00:04:20
Now I've just been practicing handstands in my room. Sometimes doors.
user avatar
Ila Fiete
00:04:26
Brian
user avatar
Bryan N Burgos
00:04:31
I'm
00:04:32
Hi, um,
00:04:35
I, I don't think I've really picked anything new up as much as I've kind of tried to work around certain hurdles that came up with the quarantine. So like once once I had enough money. I got
00:04:54
Electronic drum kit which is back there and I
00:04:59
I stopped the kit that I already had into a storage unit and kind of turn that into a rehearsal space.
00:05:07
So,
user avatar
Ila Fiete
00:05:09
Are you part of a band. Is that something you can preview or
user avatar
Bryan N Burgos
00:05:12
I'm, I'm, I'm in a I'm in one of MIT's jazz combos.
00:05:18
But I usually don't play the drums
00:05:22
Like when I first when I first joined. I
00:05:25
I was mainly playing keyboard, but I picked up the drums like two years ago. So it's I've had one gig, but it's it's mostly something that I I do on my own. Just like practice and get good enough at it to
00:05:42
To be presentable for open audience, which I think just takes a few years with any instrument.
user avatar
Steven Meisler
00:05:49
I'm actually in that same situation. I'm also an MIT jazz combos, but
00:05:54
I'm being recruited to play drums, even though I mainly play but
user avatar
Bryan N Burgos
00:06:00
I guess I guess you have the progressive aspect down you can like, you can do the strokes, but
00:06:07
Yeah, I mean, it's hard, especially jazz drumming
00:06:10
Yeah I mainly play rock like 20th century rock right now, just because it's much easier to do.
00:06:18
But like I i started playing drums because of like art Blakey use my favorite drummer.
00:06:26
But yeah
user avatar
Ila Fiete
00:06:28
Great, thank you. Say,
user avatar
Tomasz B Mloduchowski
00:06:32
Hi I'm tell us
00:06:33
I use a lot of hiking and flying around before our the quarantine and now that I'm kind of locked in one place. I ended up picking up a lot of construction skills because we ended up renovating a place that we live in. So just doing all things that you normally would have had hired
00:06:51
People to do
user avatar
Ila Fiete
00:06:55
Today truly productive, I guess.
user avatar
Tomasz B Mloduchowski
00:06:57
I guess I mean if or just new experiences to learn if you ever wondered how the inside of an attic looks like. Well now's your chance.
user avatar
Jiajia Zhao
00:07:12
I am Georgia. I'm a student of concentrating in distributed algorithms and I enjoy doing a lot of sports outdoors like running
00:07:22
Biking hiking and in the winter skiing and skating and stuff during the quarantine. That was a bit harder. Some running still but so I started trying to do some hate exercises indoors.
00:07:38
They were actually not as horrible as before, so it's good. Um,
00:07:45
I've tried to like garden. I guess like sort of plant some things. The only thing that works is scallions.
00:07:53
They're really easy to plant and they grow like crazy and you just harvest them and they just keep growing. So it's great.
user avatar
Ila Fiete
00:08:01
At the top right.
user avatar
Jiajia Zhao
00:08:02
Yeah, you just
00:08:03
Like harvest
00:08:04
The green part and then it just keeps growing, growing forever.
00:08:08
Really makes me confident
user avatar
Ila Fiete
00:08:10
Okay, stay over the winter.
user avatar
Jiajia Zhao
00:08:13
Oh,
user avatar
Ila Fiete
00:08:14
Do they stay alive over winter.
user avatar
Jiajia Zhao
00:08:16
Yeah, I mean, they're indoors, so
user avatar
Ila Fiete
00:08:19
They're indoors. Okay.
00:08:20
Yes. Wow.
00:08:23
Adam
user avatar
Adam Joseph Eisen
00:08:26
I honestly really wanted to start gardening, but I figured I couldn't because
00:08:29
I live in an apartment with no balcony. So maybe I should have tried scallions. That sounds like it would have worked
user avatar
Jiajia Zhao
00:08:34
Oh for sure they don't even need dirt. You just put them in a jar just great.
user avatar
Adam Joseph Eisen
00:08:39
Okay, well I'm gonna try that maybe
user avatar
Jiajia Zhao
00:08:41
Sunshine, Sunshine.
user avatar
Ila Fiete
00:08:42
This water and
user avatar
Adam Joseph Eisen
00:08:44
We don't get a ton of sunshine either, but maybe I can, I can
00:08:47
You know, really shattered by the window. I was I really ramped up my my running in quarantine. That was a good way to get outside. But then I threw my back out.
00:08:56
So that was a really, really put a put a nail on that but I sort of since transition to doing some some canoed shipping and that's been has been really nice lately, but it's now it's going to call. So, you know,
00:09:08
Not sure what to do about that.
user avatar
Ila Fiete
00:09:10
It getting cooler ready for you.
user avatar
Adam Joseph Eisen
00:09:12
Oh, yeah, yeah. It's really, it's not it's not good summer is quickly fading.
user avatar
Ila Fiete
00:09:17
Three to remind everybody where you are.
user avatar
Adam Joseph Eisen
00:09:19
We I'm in Toronto in Toronto.
user avatar
Ila Fiete
00:09:21
In
user avatar
Adam Joseph Eisen
00:09:22
Canada. So it's, yeah, just, I mean it's coming for for you guys in Cambridge, probably sent if that's
user avatar
Ila Fiete
00:09:28
Been summer in Cambridge, this week.
user avatar
Adam Joseph Eisen
00:09:30
Oh, nice. That's, that's likely Louis, we got a very stern reminder that it's not summer anymore.
user avatar
Ila Fiete
00:09:35
Okay. Okay, next week, then
00:09:38
Yes. Ready.
user avatar
Brody West
00:09:41
Hi I'm Brittany I'm
00:09:45
Reading a lot
00:09:46
During corn. Do you
00:09:48
Have
user avatar
Ila Fiete
00:09:54
Any
00:09:55
Any particular book you can recommend
user avatar
Brody West
00:09:58
Um, I'm finishing up a book called accelerando which I really like.
user avatar
Ila Fiete
00:10:05
Excel Toronto.
user avatar
Brody West
00:10:06
Yeah, it's a really good one. It's pretty dense, but more local book is I really liked also lose X innovation by touching. No one's pretty serious.
00:10:19
I read
user avatar
Irene Zhou
00:10:21
Hi, Irene. I really enjoy playing the Viola and painting murals. So this thing right behind me is one of the murals. I painted
00:10:30
And also this one also that one.
user avatar
Ila Fiete
00:10:33
Idea what what is the material. What is the
00:10:36
It's
user avatar
Irene Zhou
00:10:37
On the wall.
00:10:39
So,
00:10:40
Very quarantine. I was at home, which has a lot more empty walls and I do here at school.
00:10:46
So I was painting all the balls.
00:10:49
And also before quarantine. I used to climb, but obviously during quarantine. I couldn't go clubbing anymore. So, replace it with your
user avatar
Ila Fiete
00:11:01
Beautiful work cheating.
user avatar
Chi-Ning Chou
00:11:07
On kidding. I notice you 60 USD student, however, yeah. So before granting I just did a study to learn piano. Yeah, so
00:11:19
Since the condemning had fun. I have lots of time to practice piano and I also continuing to advance my cooking skill. Yeah. So I made a row stocks like a few weeks ago, which is the host. I can, I imagine, I can do it before the current. Yeah.
00:11:37
Yeah. And also I missed the free food a lot. So let's, we can make some pizza. Yeah, which you used to go like piece of butter. Yeah.
00:11:47
Now I can make it my own piece of
user avatar
Ila Fiete
00:11:49
The spectacular thing about Doc is how much fat it renders
user avatar
Chi-Ning Chou
00:11:53
Duck.
user avatar
Ila Fiete
00:11:54
Fat that comes out of the dark when you cook it.
user avatar
Chi-Ning Chou
00:11:57
That's what I thought. Yeah, yeah, yeah.
00:12:01
Like very creepy.
user avatar
Bhav Jain
00:12:07
Hi, I'm Bob I'm
00:12:10
And over cord team. I've mostly been playing tennis actually with with my brother I played a lot of tennis back in high school.
00:12:18
And it kind of stopped after I got to college. So it's been nice to kind of get back into that. Um, so, so, yeah, it's been a pretty peaceful quarantine and it's nice to meet all of you virtually every zoom
user avatar
Ila Fiete
00:12:33
Stephen
user avatar
Bhav Jain
00:12:35
Oh, we
user avatar
Ila Fiete
00:12:37
Already, go ahead.
user avatar
Steven Meisler
00:12:39
Yeah, I already want
user avatar
Ila Fiete
00:12:40
That's right.
00:12:41
That's right. And you also talked about your music so I'm
00:12:43
Sorry, I missed that one. Okay. And then finally, Christina.
user avatar
(Christina) Mingye Wang
00:12:48
Christina. So I've
00:12:50
Just been watching TV movies and reading. Pretty much, yeah.
user avatar
Ila Fiete
00:12:57
Any movies to recommend or
user avatar
(Christina) Mingye Wang
00:13:02
So as part of a group we read on Cloud Atlas and then Washington movie. So that was pretty fun and also a Good Omens, which I watched the TV and then read the book.
user avatar
Ila Fiete
00:13:12
Okay. Oh, and that order to not mess it up for you.
user avatar
(Christina) Mingye Wang
00:13:15
It was actually helpful because people who started with a book was really confused because they had, like, about five different storylines and like I watched the TV so I knew what was going on those fun
user avatar
Ila Fiete
00:13:25
Okay, that's great. Well, wonderful, thank you for sharing something about yourself. I really feel that, you know, and without the, you know, seeing your face to face. I can learn a little bit about you and hopefully learn a little bit about each other and
00:13:38
So don't forget one other thing I want to remind you is we have you scheduled zoom times for social zooms and you know it's not moderated i mean
00:13:48
The tea and i thought i or not, you know, planning to be there. It's just for you. It's your own space if you want to, you know, discuss anything
00:13:55
In lieu of setting up formal homework groups, but you know if you have your homework groups, that's fine too but it's available for you and the times and the zoom links are posted on the website. Okay. So without much ado I want to now start, you know, talking about some of the things that
00:14:11
I wanted to talk about today. So I'm going to go back and share my screen and
00:14:17
Let's
00:14:22
Okay. So, um, what I want to talk about today is the derivation of neural network equations, starting from single neuron biophysics. So the question is, you know, how do we get these neural network equations.
00:14:37
You know, can be derived somewhat formally or reduction into these rate based neurons and equations that are commonly used in modeling neural circuits.
00:14:48
So, before going to the single neuron biophysics. I just wanted to give you some, you know, really quick.
00:14:54
Fun fact so neurons and numbers in the human brain. So the human brain is about three pounds. The brain is two to three pounds of our body weight but consumes 20% of the energy and oxygen use of our bodies.
00:15:06
There are about
00:15:08
100 billion neurons in the human brains tend to 11 and the breakdown here is about 10 to the 10 in cerebral cortex. A lot of cerebral cortical neurons, but then strongly outnumbered by the amount of neurons in the cerebellum tend to the 11th and cerebellum.
00:15:25
By the way, is my participant bar blocking your view of the slides.
user avatar
Eric J Pence
00:15:33
Now we see
user avatar
Ila Fiete
00:15:35
Okay, so you don't see the faces the participant view that I see.
user avatar
Eric J Pence
00:15:40
Correct. Good.
user avatar
Ila Fiete
00:15:42
All right. And then there's um number synopsis this 10 to 100 trillion synapses. So tend to the 13 to 10 to the 14 synapses in the human brain. So, you know, assuming something like one bit per cent apps, you know, streaming per I didn't know per you know time constant. That's about 10 terabytes.
00:16:01
Or point one pet a bit of information that you know can principle be, you know, processed in the brain, you know, each time constant
00:16:11
So synopsis of sparse is only 10 to 100 synopsis printer on, so that's extremely far away from also all connectivity, like we as human
00:16:20
Often in building artificial neural network models very, you know, everything is also all connected. So this gives you a sense of how how incredibly sparse neural circuitry is
00:16:31
What are the sizes of cells in the brain while they're about 10 microns. The soma, the cell body and and and so so that's that's approximately
00:16:42
The, the scale of the of the soma, but on the other hand, if we consider the length of, you know, the axon, the ongoing process of neurons. These can be extremely long it can go up to one meter in length. And there's some really nice full tracings of
00:17:00
Neurons within even the brain within the central nervous system in in this application called Mouse light from generally have farms, actually I'll link to that later. In today's class but
00:17:11
It has really beautiful images of collateral within brain of single neurons, but the the one meter along axon is the one that is the descending axon that goes from, you know,
00:17:24
From from the, from the brain to controlling from your spinal cord from your brain through the spinal cord to control for example your big toe on your feet. So that's, that's an extremely long axon right there.
00:17:41
All right. And what about brain scaling. So if you look at brands across species. So this is just something very quick. You can look up a lot more information about this.
00:17:52
From these references that I've given below. But if you look at brain weight as a function of body weight. You can see that there's
00:17:59
A nice parallel relationship. So this is a log log plot. And then this is a linear curve on that. So there's a nice part of our relationship between brain weight and body weight. Are we here and here's where everybody falls.
00:18:14
And however if we then look at where humans are on the scale. So here's humans over here. And so if you've got body weight versus brainwave on this log log plot. You can see that they're a little bit off the curve. So humans proportional to their body size have larger brains in proportion
00:18:38
Brains scaling again across species. So if we look at, you know, total number of neurons just, you know, in numbers, rather than weights, then
00:18:46
Elephants actually have a very large number of neurons total much larger number than humans their actual brain mass is of course also much bigger than humans.
00:18:58
A lot of that brain mass is in the cerebellum of the of the elephant. So here are two images of a human brain and an elephant brain. And you can see that one of the biggest
00:19:11
Differences between the human and the elephant brain is the sheer size of elephants or MLM so cerebellum is
00:19:19
Very important for motor control and coordination and modal learning and so
00:19:25
Presumably, I mean, one of the hypotheses is that they just have a lot more muscles. Rather, it's bigger. They have a lot of muscle mass, a lot of muscles to control and then they've also got, you know, their trunks, which they have a lot of control.
00:19:37
Signals that have to control the trunk. So, for whatever detail reason. But this is a major difference. And if you look at
00:19:46
Numbers of neurons us in raw numbers in cerebral cortex, then even though elephant brains are bigger in math and bigger in total number of neurons, but they have a smaller number of cortical neurons. So
00:20:00
Cerebral cortex neurons compared to humans. So humans here strongly on number most other animals. So it's really their cerebral cortex or the outer sheet of neural tissue that is expanded in the humans.
00:20:15
Okay, so those were just some very overall facts about the brain. And so let's now talk about neurons and single neuron equations.
00:20:26
Okay, so before we get to actually equations. One thing we have to appreciate about neurons is the morphology. So this is
00:20:36
Just a sampling of five different types that are found in mammalian brains and these are taken from drawings by a hall and you can see the huge diversity in the neurons.
00:20:51
Look at these five neurons and also look at the scale of bars, they're actually quite different on the scale bars are 15 micrometers. Some of these scale bars are 500 microns. So A and B.
00:21:01
There's a factor of 10 difference in the size of the of the neuron and the radius or with your projects.
00:21:07
And then there's also the morphology. So this neuron out here on the left is in the cerebellum and these neurons have basically a two dimensional dendritic arbor ization so it's this big flat curtain like dendritic arbor.
00:21:25
But it's entirely in two dimensions. And these neurons are stacked one after the other in the cerebellum.
00:21:32
Okay and so and so you can see those differences, not only in size but in shape and overall just qualitative morphology. So there's really, really.
00:21:44
complex structure in the in the dendritic trees of these neurons.
00:21:47
And now it's a similar set of neurons that are plotted here, but now the axons are colored in red. So what you saw previously where the den rights which were the input ends to the neurons and now these axons.
00:21:58
These are the output ends of the neurons which send their signals post processing out to their
00:22:04
Partners and you can see that the axons are, you know, are more straight and these unless branch and then the den rights over here. So these are examples of the axon processes of these very different neurons.
00:22:19
Again, feel free to jump in with questions. If you have questions just speak up because I can't see all your faces while I have these slides.
00:22:34
Okay so clearly neurons have, you know, very high morphological complexity and so the only way to make progress in modeling neurons is to make
00:22:44
Some pretty drastic simplification. So let's just simplify the neuron to some of its very basic components and say that the neuron consists, it's a cell. It consists of a cell body consists of
00:22:55
Cell membrane. In addition, it's got gun rights, which are the input and and then it's got this basal
00:23:04
Part of this axon, the output end of the neurons as bazell parties where spikes are initiated and the axon then terminates in in in connections to other neurons and to facilitate signal flow to facilitate the speed of signal transmission along the axon.
00:23:22
Some cells. Some neurons in the brain have this mile encoding or my island sheet which
00:23:29
Which which is basically an insulator and it insulates the the the
00:23:35
This get this axon from electrical leak and allows the signal to propagate more rapidly than without. So usually the cells that have very long excellence are the ones that are my eliminated.
00:23:48
And there's many neuro degenerative diseases that are involved that that that involves degeneration of these models and sheets.
00:23:58
And okay so so that's, you know, the, you know, stripped down to the simplest description. A cell has, you know, this nucleus, which is you know where all the genetic material is and
00:24:10
A lot of the all the you know the the genetic
00:24:15
Information is read out from the chromosomes in the nucleus. And then it's used to then just like in basic cell biology. It's used to
00:24:26
produce proteins and support cell function and
00:24:31
learning processes also require so if there's a change in the synaptic weights of a neuron. Then if all if many of the synopsis gets strengthened it'll require
00:24:42
The building of the snaps in size and building up of the snacks and size which presumably then requires more resources from the cell Soma to support
00:24:51
That bigger sin apps, right. So there's got to be some interaction and learning between the cell soma, the cell nucleus and the rest of the cell. So some aspects of learning are also have to be then transmitted to the to the to the nucleus to be able to support long term memory and learning.
00:25:13
Okay, so what is the basic electrophysiology of a cell. What, how does a cell work. And so these neurons work by transmitting electrical signals.
00:25:25
Or actually, the compute internally with electrical signals and then they transmit information either electrically organically. Okay, so we'll just take
00:25:32
A TOUR a brief overview of some of the principles.
00:25:36
Behind on your activity, these, this is not a basic neuro physiology class. So I'm not going to go into this in detail, but I just want to give a broad overview. Before we introduce some of the equation. So, all right. So cells use membrane pumps.
00:25:51
Which you consume energy in the form of ATP to actively maintained chemical gradients across the cell membrane. So, so that is what
00:26:01
Neurons do so they are actively maintaining this chemical gradient
00:26:05
Of different ionic species. And here are the various ionic species for which these membrane pumps actively maintained chemical gradients, so
00:26:14
Cells pump out sodium and so that outside it's 145 millimeter molar. And inside. It's about a factor of 10 or 12 million molar, and they pump in potassium and maintain almost 100 fold like you know at least
00:26:30
Like you know tenfold of difference between the inside and the outside and potassium and with calcium they maintain a huge difference in calcium storage.
00:26:41
In calcium concentration. So the they pump out calcium so that the outside is of order one millimeter, but inside. It's only 10 to the minus form.
00:26:50
Right, so it's a huge gradient in calcium and these three ions are extremely important than for cell signaling in and neural neural excitation
00:27:04
So, okay. So in the resting state there is a ionic segregation and that ionic segregation of this of these iconic species.
00:27:14
Lead to a potential difference of voltage potential difference across the cell membrane. So these pumps again use ATP to maintain the differences
00:27:21
And now these chemical differences automatically set up a voltage difference across the cell, according to the nerds potential. So the neural chemical potential is a voltage potential that's induced
00:27:34
By segregating charge ionic species across a membrane. So basically the idea is that if you're moving charges across a member in and you're separating charge
00:27:47
Then you're maintaining but you also maintaining so you're maintaining a chemical potential by moving ionic species across the membrane.
00:27:53
And then that chemical potential difference has to also be balanced by then a voltage potential difference. And so it's this balance between chemical potential and voltage potential that
00:28:03
Gives rise to the utterance equation and gives a tells us what the resting potential of a cell should be so here
00:28:11
This is just the nearest equation that says that for a single iconic species. So if there's an iconic species A
00:28:18
And I pump out the ionic species and maintain a concentration. A out outside the membrane and a in inside the membrane.
00:28:25
On the other side, then there will be this voltage drop across the membrane. As a result, so he he refers to the, the electron, the charge of the single electron Z is the number of charges and that species to calcium would have to sodium and I have one.
00:28:39
T is the temperature and Calvin and kB is the Boltzmann constant. So in other words, the voltage drop across a membrane is proportional to the log of the concentration difference across the membrane and then times these fundamental constants that set like the overall scale and the units.
00:28:57
Okay, so. So the bigger the chemical gradient, the bigger the voltage gradient, the bigger the charge of the ionic species.
00:29:06
Then, the smaller the voltage difference here for given chemical difference. So, so this is the relationship and this is for a single species chemical species, but
00:29:20
There's a generalization to multiple ionic species. So, and to non equilibrium scenario. So this generalization as the Goldman Hodgkin hopefully potential and you can find more information about
00:29:33
The resting potential of the cell and how it's derived based on segregation of multiple iconic species in, for example, this nice textbook Jasmine.
00:29:42
So, but as a result of segregation of these multiple species, a cell a neuron at rest across the different cell types. So these various cell types that we see more or less have a resting voltage have close to minus 55 two minus 60 mobiles relative to the outside.
00:30:08
Okay, so that's at rest. And this is an equilibrium at rest. So the cell is that I saw potential. So the whole cell has the same voltage
00:30:17
Relative voltage relative to the outside. Now this that the okay so so cells can sit there and rest. But another thing that cell can do is it can be active and and firing action potential. So these neurons have this
00:30:35
Polarization that maintains so that the resting will just negative and, on the other hand, once a solid sufficiently excited
00:30:43
It unleashes this very nonlinear event called an action potential. So this is a plot in time of what action potential looks like. So on the
00:30:51
X axis. We've got time in milliseconds. And on the y axis we've got this potential difference between the entire business on the outside. So at rest. It's sitting at something like, you know, somewhere between minus 55 and minus 70 milliwatts and
00:31:06
If it received some input some stimulus that excited excited to read, which means that it drives the cell towards a deep polarization, a little bit, then
00:31:17
If the the polarization input is small enough, the cell, it does the stimulus applied in the deeper realization is small enough, then the cell may respond briefly but then go back to its resting value.
00:31:28
But if the stimulus is strong enough, if it's a big enough stimulus.
00:31:32
Then it leads it kicks the cell enough towards say this threshold over here. So, so here are some failed inputs that are too small to really drive any big nonlinear event.
00:31:43
But if the stimulus is large enough so that the the cell membrane depot rises towards this value call the threshold, then the cell internally through dynamics.
00:31:54
That are nonlinear unleashes this very nonlinear event, which is called an action potential. So this is an accelerating.
00:32:04
The polarization that once a certain threshold values reached the cell. It's like an all or none.
00:32:12
You know event that just happens. So it unleashes this big action potential and action potential has a deeper realization phase a repo realization phase.
00:32:21
And then it actually dips below in what's called refractory period and many neurons. Not all neurons have the same refractory period. So the details shape of the refractory period is a characteristic of different cell types.
00:32:32
So the refractory period and then over lot slightly longer timescale, the cell returns to its resting value.
00:32:41
So this is overall, the, the, the, the shape of an action potential in a typical central nervous system in Iran.
00:32:51
So um okay so this is what what happens when a seller sufficiently excited it unleashes his action potential. And then this action potential travels down the axon in a in a wave like a solid time so it goes through undiminished so it just
00:33:06
Moves through the, the act of the axon in an active process that regenerates the wave and keeps it going in the same shape. So the shape is not attenuated
00:33:16
As it moves down. So this is
00:33:19
One. The first recording of an action potential by an electro that was inserted into the axon of a giant squid. So this was the squid giant axon, it was big enough to actually just manually insert the electrode into and record. And this is a screenshot.
00:33:33
Of of of the first recording of this action potential, which then one Hodgkin Huxley
00:33:40
A Nobel Prize in 1963 together with the modeling work so hard. You can actually build these very detailed biophysical models of how this action potential can happen. And so that is that together the recordings is one them the Nobel Prize.
00:33:58
Okay, so once this action potential is triggered in a neuron and this action potential travels down the axon.
00:34:05
What is the signal that actually is communicated from that neuron to its partners that it connects do
00:34:12
So this is now the chemical snap. So although the event of an action potential is electrical event. Most signaling the central nervous system is through a chemical medium. So what happens is
00:34:26
Here's the present optic neuron. If it's excited sufficiently and unleashes an action potential, which then travels down the axon. And once it reaches the terminal termini of the axon these these these terminal ends there. There is a whole process a molecular
00:34:46
cascade that leads to the release of chemicals or neurotransmitters.
00:34:50
Into the synaptic cleft in between a pair of neurons. And then these chemicals, go and bind to the post synaptic neuron, thereby signaling that this prismatic neuron was active. So once those. Okay, so let's look a little bit more detail at what this chemical snaps looks like.
00:35:08
Okay, so here in a bit more detail, then, is this picture of a chemical sin apps. So this is again the pre synaptic neuron here is it here, it's done right it's it's axons. This is the myelin sheath over here, this is
00:35:22
The action potential. And again, if you record the action potential early up
00:35:29
high up in the axon, where the action potentials initiated or later. Later down when the action potential is
00:35:36
Propagated some distance down. You see, and undiminished action potential shape. So it's really kind of like this.
00:35:42
All or non binary shape that's regenerated and stays exactly the same way. So you can think about this action potential is sort of a binary event that was a spike it was not a spike the shape the details don't matter very much. Okay, so now what happens is, now here's a
00:35:57
You know, the axon terminus and here we're going to be zooming in to the synapse over here. Okay, so what happens though at a high level is once this action potential invades this
00:36:09
This axon terminal over here, then a whole series of molecular reactions happen that then lead to an occurrence to enter into the post synaptic neuron and that causes a deeper realization of the post synaptic cell and that the polarization is called a synaptic potential
00:36:29
Me. Yes.
00:36:31
Yeah, go ahead.
user avatar
Annika L Heuser
00:36:32
Why are there so many different types of neuro transmitters and why couldn't the system just use one single type of neurotransmitter for every type of neuron.
user avatar
Ila Fiete
00:36:41
That is, is a very good question. So there are certainly multiple synaptic transmitters neurotransmitters and they have different properties. So one, one thing you know
00:36:53
Some of the differences are timescales, it gives you the ability to signal at, you know, you know, signal rapidly.
00:37:00
Or have more extended and slow responses. So the different neurotransmitters. Well, the first main difference between neurotransmitters and we'll talk briefly about this. I'll come back to that.
00:37:10
One difference between neurotransmitters is whether their effect on the post synaptic neuron is excited. Tori or inhibitory so a given neuron any neuron recent happy neuron only releases excited during your transmitters or it only
00:37:26
Only
00:37:29
Contains inhibitory neurotransmitters that it that it puts out. So a given cell can only can always just inhibit all its partners or it can excite all its partners a cell can do both typically
00:37:41
So I think there's been one or two exceptions that have been found, but almost every cell in in in almost every cell in almost every brain.
00:37:48
Of mammals and insects is is exclusively excited to reorient inventory. So the first big difference when the neurotransmitters is there effect.
00:37:56
Whether it's excited Kareena Dory. And then within those there's differences in how they, in their time constants and also in how they affect the post neck around and we'll talk about that briefly.
00:38:07
So yeah, I bet it's a great question. But, so, so, so there are some important differences which give them different potential functions.
00:38:14
But why those are strictly necessary. I don't think we have a comprehensive theory of that. So come back to me and tell me if you want more details when I when I discussed those properties.
user avatar
Bhav Jain
00:38:27
Um, I have another question. I'm just curious on so like basically
00:38:32
There's this idea that like the actual magnitude of the action potential is is relatively on diminished over the whole course of its propagation
00:38:41
But I mean, isn't it true that like there's I guess some level of leakage. So have there been experiments which actually show like a significant degrading effect of the strength of the action potential over time or
user avatar
Ila Fiete
00:38:54
That the great questions. If this were a
00:38:56
passive process.
00:38:58
So if this if you just thought about the axon, as some kind of a wire as just a wire just, you know, it's just a resistive wire.
00:39:07
With maybe some capacitance. You could compute. So that's called that that is a passive excellent model and you can actually compute how if you start out an action potential here and then just propagate it down.
00:39:18
A resistive and maybe capacitive wire. What, what would happen to to the action potential, it would it would spread out and it's amplitude to decrease, right, it would be kind of a diffuse of looking spreading and
00:39:31
To decrease. But in fact, it's not a passive electrical process. Its regenerative. So in fact, one thing I should point out is in these
00:39:40
It with this myelin sheath there. Nevertheless, these these these things called nodes around here, which are breaks in the myelin sheath and those brakes are important because this is where
00:39:50
There are high density of ion channels present in the in those locations and there the action potential is fully regenerated from scratch. It's as though, so it's a regenerative event. It's a very nonlinear and non passive event that that works to counteract any
00:40:08
Loss of the signal in the in the
00:40:11
In the action potential.
user avatar
Bhav Jain
00:40:12
So is it accurate to say that it it kind of the grades over the short scale until you then like reach like a region of that as high density amount you
user avatar
Ila Fiete
00:40:23
Know, I think, I think that's probably accurate and and that's a good question. In fact, and also there are
00:40:28
Axons which are not my limited and
00:40:31
But, but they tend to be very short. So in order to have a signal propagation over you know longer distances, you need the
00:40:38
The myelination to for speed up the process, the propagation of the of the signal. But even in cells that don't have myelination there is still regenerative dynamics in the axon. So the axon and all cases is a regenerative
00:40:51
Is a regenerative membrane. And so yeah, so I think cells, you know, really seem to be optimized for, you know, this all or none sort of action potential propagation, I think, to lowest order that is the case.
00:41:08
Okay, so what is going on in that, you know, accidental terminal.
00:41:13
Where the pre synaptic neuron comes to close contact with the post synaptic neuron. So first of all, this is a zoom in.
00:41:21
cartoon of a chemical snaps. So this is the pre synaptic terminal end of an axon. This is the post synaptic neurons dendritic
00:41:30
dendritic spine. So, so this call the baton and axon Bhutanese. This is called the dendritic spine and the post synaptic neuron and these cells don't actually touch but they come very close. So there is this space in the middle, which is
00:41:46
I think about 30 or 40 nanometers wide. So it's a very small in in in intracellular space in this region. So now what happens is when an action potential comes into
00:42:01
The, the boot on here, the terminal of this axon. What happens is it triggers the opening of these voltage gated calcium channels. So these are
00:42:14
So these are channels that open when this cell membrane is sufficiently polarized. So they let calcium in flux.
00:42:24
Happen into the cell. And remember that calcium is highly regulated in cells because it's like 10 to the minus for concentration less right it's 10 to the minus $4 million compared to the outside, which is a word one
00:42:38
So so Kasim comes in. And then once calcium comes in, it binds to these facts which remember insects filled with neuro transmitter and then
00:42:48
And then that leads to this process of these bicycles or sacks fusing with these proteins is docking proteins and the docking proteins then fuse the membrane of the vehicle to the outer membrane of the cell.
00:43:02
Thereby dumping all the contents of that bicycle out into that.
00:43:07
intracellular space in the setups and now this is just a passive diffusion process of these molecules they diffuse and then bind to receptors on the on the post synaptic neuron and now these are neurotransmitter, like in gated ion channels which then open up and allow
00:43:27
It to flow into the post synaptic neuron and D polarize it or hyper polarized and depending on which island is allowed to flow in
00:43:38
Okay, so then whether a neuron has an exciting story or inhibitory effect on its neighbors. It depends on the variety of neurotransmitter that it produces
00:43:45
And this is what we were discussing just briefly and response to this question, Dale's law is that a neuron either excites all it's an active contact or inhibits all of them.
00:43:55
So the chemical snaps is a is very directed it's flexible in plastic because the number and density and size of these
00:44:04
These, these, these synapses, the number of contacts between the pre and the post synaptic neuron. The area of this region, the density of receptors in this region are all
00:44:16
controllable by the cell. So there's a lot of flexibility or plasticity and the signaling between pre and post synaptic neurons through these chemicals synapses.
00:44:25
And the excitation, or of the prison haptic neuron can lead to expectation or inhibition of the target depending on which neurotransmitters released because the, the, the chemical species determines which receptor, it binds to which determines which islands, make it into the cell.
00:44:43
Have a question. Yeah.
user avatar
Jiajia Zhao
00:44:45
Sorry. So if one you're on can
00:44:49
Either inhibit or excite like all of its contacts like only one of them. Does that mean it only has like one type of neurotransmitter
user avatar
Ila Fiete
00:44:59
Correct. That's exactly right. So each neuron.
00:45:01
Sense to only make 110 yes what one family of neurotransmitters. Yeah, they usually will make Yeah, they'll make the make the excited to a neurotransmitter or the inhibitory neurotransmitter
user avatar
Jiajia Zhao
00:45:13
Okay, interesting.
user avatar
Ila Fiete
00:45:14
And I think as far as I know, there's only one example one neuron example that actually manufacturers excited to be an inhibitory neurotransmitter
user avatar
Jiajia Zhao
00:45:23
Oh, I see.
user avatar
Ila Fiete
00:45:25
If that is the exception that proves the you know deals law.
user avatar
Brody West
00:45:31
Okay, but, um, so can you give a neuron.
00:45:36
Produce multiple excited or exciting toward their transmitters. Is that a common occurrence.
user avatar
Ila Fiete
00:45:42
Oh, okay. That's that is actually a good question. So can the same neuron produce both glutamate, you know, so, I'm sorry. So
00:45:53
There's um so for it for the standard excited to a neurotransmitter glutamate can actually buying two different post synaptic receptors so it's it's a single neurotransmitter, but they're to receptors that that neurotransmitter binds to so there's amber receptors and glutamate.
00:46:11
And in this app receptors and and amp D receptors. There's two different types. So the same glutamate, you know, the same neurotransmitter can have two different effects on the person happy neuron.
00:46:21
Depending on which receptor, the post synaptic neuron Express. So let me explain that a bit here. And so that's the default
00:46:28
So yours. He excited to our transmitters. So one is
00:46:32
Glutamate
user avatar
Brody West
00:46:32
It's an amino acid.
user avatar
Ila Fiete
00:46:34
And glutamate can bind to two different receptor types at least
00:46:39
The Amber receptor and the NBA receptor. Okay, so in broad brushstrokes, these are the two classes of glutamate receptors and the apple receptor is something that's fast so it takes
00:46:49
Its rise time and decay time it's all done in five milliseconds. So, you know, one action potential can lead to a five most I can event in the post synaptic neuron if glutamate is released and Grandpa.
00:47:02
The enemy receptor is something that's slow. So all these these rates are determined by the binding time constant of the lie again onto the onto the channels.
00:47:12
And so, this one has a time scale of approximately 50 milliseconds. So the same neurotransmitter can have disparate effect, depending on the receptor on the post synaptic neuron does not only one kind of
00:47:25
Excited your neurotransmitters.
00:47:26
Glutamate better than this acetylcholine and typically runs a generator that release glutamate, do not release acetylcholine.
00:47:33
I don't know what the literature is on whether there are any neurons that release both glutamate and acetylcholine, both of which are excited during your transmitters. So that is a good question, and it's something I can can do
00:47:47
So okay, so another kind of excited to our neurotransmitters acetylcholine also yeah so so that's one and now key inhibitory neurotransmitters.
00:47:56
There's um there's, um, so it's glycine is an amino acid and and Gabba is also an amino acid and Gabba has two types of receptors. Again, just like glutamate have to receptor types.
00:48:11
Gabba has gathered a which is a fast receptor, again, five minutes that can time constant but Gabba be is a slow one and it has about 100 millisecond time constant
00:48:22
Okay. And then there were various other neurotransmitters and they have they have again a range of different time constantly having a range of different effects. So now this is not the only difference between
00:48:34
These receptors. So it turns out that all the glutamate effect with an MBA, there's, there's an important difference in how glutamate effects. Those two so
00:48:45
Requires just glutamate to to to open. So if glutamate is present. The amorous actors will open and depot rights to sell.
00:48:55
It if glutamate is present and binds to an end MDA channel. It's not necessarily that the cell will be polarized. It actually requires an MBA is is a is an aggregate
00:49:06
And an MBA channel only allows ions to flow in and D polarize the cell if glutamate is present and the cell has already been sufficiently be polarized because of some other event, for example through some
00:49:18
Activation so MDA says it is an AND gate between glutamate input and already the cell being D polarized a bit
00:49:31
So, so you can see now that the complexity of signaling is quite high.
00:49:36
Because the same neurotransmitter is now doing things at different times skills and also those receptors apply different kinds of logic in in their action in response to those neurotransmitters. So the complexity is vast.
00:49:54
Okay so rough time scale. So I gave you some time scales for these different synaptic
00:50:01
Channel opening events. Now, what, how does that compare to some other time constants in in in on the neural level.
00:50:09
So the neural membrane time constant is approximately 10 to 30 milliseconds. So the neuron itself.
00:50:15
A you know has a certain time constant. If you're excited the neuron. The sometimes skilled with which then you're on will go back to its resting potential right because of these active pumps pump out the the the the
00:50:29
The ions, but also because of the membrane, which is capacity and we'll talk about the next. So, so anyway, so the memory of a neuron. It has a time concept of of
00:50:39
10 to 30 milliseconds. So it's right in between the fast synaptic time scales and the slow synaptic time skills, it's somewhere in there.
00:50:45
And action potential has a width of about one millisecond. You saw that in the drawing that I showed you earlier.
00:50:50
post synaptic potential decay time constants are likely saw like five more seconds for the fast receptors 200 milliseconds for the slow ones.
00:50:59
Cross brain conduction. So if you want. If you haven't, Iran has an accent. It goes from one of the brain to the other side, one side of the brain to the other.
00:51:06
The, the delays or latency is can be tend to 200 milliseconds. So that's approximately
00:51:13
The times because we're talking about typically like 10 milliseconds 200 milliseconds happens when this multi synaptic contact. So if you want
00:51:20
A signal from one side of the brain to reach the other side, but it goes beyond multiple synaptic contacts so electrical, mechanical to electrical, mechanical than it can take hundreds of milliseconds.
00:51:30
Okay. And then finally, the long time scale within single cells is one of protein degradation or turnover, which is on the time scale of one hour to a day. So that's a very slow time scale within single cells.
00:51:42
Now, on the other hand on the level of the brain wide or behavior. Why timescales.
00:51:47
There much longer time constant so timescales of short term memory. For example, you read enough phone number and you can remember it for a few seconds before you completely forget it. So that's
00:51:57
Short term memory is in the time scale of a few you know 10s 201 to about on with seconds and then long term memory, the things that we learn and then
00:52:07
Remember can be remembered for hours to, you know, 10s of years. So up to a scale of about 100 years so it just goes to show you the tremendous range of
00:52:18
Skills in the brain. We have neurons, who is single components are very, very short timescale components and their dynamics evolve rapidly and
00:52:31
And even the slowest time skills.
00:52:33
Of protein degradation and turnover is just on the number of hours and days.
00:52:37
And yet somehow the system is
00:52:40
Then able to construct behavioral outputs on the time scale of seconds to hundreds of seconds to 10s of years, so it's it's a big span of time skills to to go over right with these very memory list components.
user avatar
Annika L Heuser
00:52:58
Are this the time scale for neuron turnover, the same as in one day to an hour or is it, do they last longer.
user avatar
Ila Fiete
00:53:06
Neurons last much longer. So in fact, most of the neurons in the adult brain are the neurons you had as a child and they're not replenished. So neurons that die or never.
00:53:20
I never replenished and and there's David through your whole life. There's a little bit of neurogenesis in adult humans, but it's largely confined to just one or two brain areas. So most of the neurons that you have are the ones that you had as a child and
00:53:34
There was a lot of pruning that happen, and those
00:53:37
You know, so there's an abundance of neurons over abundance. There's a lot of synaptic pruning and some neural imprinting and then finally the adult neurons just
00:53:46
last for decades. So yeah, so you're right. So there is sort of structural stability on the level of on hold neurons. But somehow, there are some components seem to be turning over pretty fast.
user avatar
Bhav Jain
00:53:57
Under the
user avatar
Jiajia Zhao
00:53:57
Health of sort
00:54:01
Of okay um, how do the time different time scales come into effect when you're trying to model these in a neuro circuit, generally, is there a lot of waiting around
user avatar
Ila Fiete
00:54:14
Yeah, yeah. So that's a great question. So we'll talk actually will address how
00:54:19
You know, our goal is to try to understand how you can go from the biophysics of these fast events to then building long time scale, you know, properties and circuits. And so that's exactly what we're going to, you know, discuss more and you'll start discussing
user avatar
Bhav Jain
00:54:34
Other than the hippocampus. What other parts of the brain exhibit neurogenesis in the adult brain because you mentioned like multiple regions might have this activity.
user avatar
Ila Fiete
00:54:46
I mean, so I think the the definitive finding is that the dental Gyrus in the adult brain.
00:54:51
Has neurogenesis. And that's the the main brain area that shows neurogenesis. Of course, it's always tough to say to rule out that other places don't have neurogenesis. But I think the
00:55:02
The recent example like that. So the example that is well accepted as exhibiting any significant amount of neurogenesis and the human brain isn't NT Jarvis, which is a field of the hippocampus.
user avatar
Bhav Jain
00:55:14
And and even in the dental chairs. Is it like as if like most of the neurons are being turned over, or is it only a small proportion
user avatar
Ila Fiete
00:55:22
No, it's not. Most of the neurons. It's, it's a small fraction that are. Yeah.
00:55:28
There's new newborn neurons that are being inserted. Now, other other animals, like for example songbirds.
00:55:34
There, there's some songbirds that have seasonal variation in their song. So there's some birds that remember their songs for lifetime zebra finch is will learn their song ones. And remember them for a lifetime.
00:55:44
Those birds don't exhibit neurogenesis. But then canaries learn their songs seasonally. So every season that they're in their song and then in the winter.
00:55:53
And they stopped producing song. And in fact, the song areas atrophy over that time and they're not producing song in the winter.
00:56:01
And then there's neurogenesis again in the early spring that then replenishes the neurons in the song areas, allowing the bird to sing again.
00:56:09
So that's an example of, you know, and it's a pretty you know you know significant fraction of the birds brain these you know song areas and they have a fair amount of neurogenesis. So
00:56:22
I think neurogenesis is not, you know, I mean, or the the rarity of neurogenesis is the human brain is is really a human thing, and there must be a lot of variation across species at least there is that one example of the songbird
user avatar
Bhav Jain
00:56:38
So assuming that the actual song is like staying unchanged from year to year. Is that a correct assumption that like like this specific song is
user avatar
Ila Fiete
00:56:47
Yeah, that's, that's a fascinating question. So it turns out that for canaries, the song is is is individually specific but it seems to be largely preserved.
00:56:58
You know, even though the song neurons are lost. And the question is, where is that in memory storage and then. So yeah, these are all fantastic questions. We don't know the answer to that. We don't know how it is that
00:57:10
Even though the neurons are loss, but nevertheless when it rebuilds it song every season it rebuilds largely the same song so
00:57:22
Okay, so let's talk about some simple single neuron models. Okay, so, so, so it turns out that well below threshold. So when a cell is close to its
user avatar
Bhav Jain
00:57:34
resting potential of
00:57:35
You know,
user avatar
Ila Fiete
00:57:37
About minus 16 multiples.
00:57:40
So well below that action potential threshold does cell memory dynamics are very well model by a simple RC circuit. So in other words, the neuron looks
00:57:49
Very much like just a passive simple RC circuit, but the battery. Okay, so here's our equivalent circuit for a cell membrane that sits well below action potential threshold so
00:58:00
This is this. So a cell membrane is a violet there that's insulating and it separates
00:58:08
chalked right because you've got some any concentration outside on a concentration inside. So really a cell membrane is this capacitive thing.
00:58:16
That has a capacitance. It's got a resistance because you know it's it's an insulator. So it's got some resistance and, moreover, if you can, there is a battery.
00:58:27
Which I'm going to call the some M for a membrane voltage battery and this battery is actually the, the, the, the, it's this battery is powered by those ATP driven
00:58:40
trans membrane pumps that are maintaining that resting potential themselves, right. These are the pumps that are, you know, putting
00:58:46
Calcium out of the cell, putting potassium inside the cell, etc. So, so it's that active process of constantly maintaining the cell of this membrane potential, potential this resting memory potential that is the battery. Okay, so in other words we can describe the cell and
00:59:03
Okay, so, so we can describe the cell in this way. So we've got
00:59:08
The inside of the cell, the outside of the cell capacitance across the cell membrane resistance across this membrane and a battery across the cell membrane. So then if we accept that this is the model for a neuron.
00:59:21
Then
00:59:23
That it's an RC circuit, then we can in a straightforward way use our elementary physics to write down the the differential equation to describe the RC circuit. So the RC circuit is that the the the current. So see DVD t
00:59:38
Is equal to and then this is the current across the. So this is the
00:59:44
The conductance across the
00:59:47
Membrane times the voltage drop and then plus any other applied currents. So here, this symbol here is some kind of variable applied current that can be applied either externally by an experimenter doing an experiment or it could be currents that are
01:00:03
Driven by external inputs through the synapses, or it could also be currents that are generated by the cell itself. For example, during the action potential.
01:00:13
Okay, so, so, so this is G membrane is the resistance of the cell membrane.
01:00:21
You know, without these other our current these other channels open. So let's just forget about the current for a moment. These other currents and let's just look at, then the cell dynamics during rest. So again, this capacity equation. So let's look at that. So, okay. So basically,
01:00:42
Basically we're making an assumption here that the whole cell can be described by one variable, which is the voltage drop across the cell membrane.
01:00:51
Okay. And this is a big simplification because like we saw cells are these spatially complex objects that have very narrow branch dendritic structures and
01:01:02
You know, the voltage here, it need not be the voltage up there. So the cell need not to be an ISO potential
01:01:10
And in fact, typically it's not if there's fast rapid changing of the voltage in the summer because it takes time for this voltage changes to propagate into the dendrites and and those, you know, and
01:01:22
Right, so. So in general, it's not
01:01:25
The right assumption to treat a seller's at high potential, but that is one of the major simplifying assumptions we can make. So you can think about that assumption as an assumption that the neuron remodeling is appointing Iran. So it's just a big membrane stack.
01:01:40
With ions inside and outside and and therefore it can be an ISO potential because it doesn't have a narrow brand structure.
01:01:50
Okay, so this. So now the question is, okay, what if we wanted to describe a cell with more detailed will judge spatially very voltages
01:01:58
How would you do that. So we're not actually going to do this, but I just want to give you a very high level view of how you do this. So you take the local capacity model of the cell membrane.
01:02:08
And just make multiple copies of it, right. So, so if we consider that. So, so we consider here is a neuron with with long
01:02:20
Den rights. So now you can break down each den right into. It's a little ice a potential component. Okay, so each cylinder here is one is a potential
01:02:29
Compartment or chamber and now these different chambers are connected to each other resistive Lee.
01:02:35
With a resistor. So that's the idea. Right. So you've got some ice potential chambers and each chamber has its own capacitive properties. And then there are a couple of resistive Lee to define a den right
01:02:49
Okay. And so then you can, one can build. So you're here is then. So this is
01:02:54
Just the, the morphology of the neuron here is just a box and line kind of diagram of these multiple ISO potential compartments connected together.
01:03:03
And now here is the equivalent circuit model each compartment is its own RC circuit and each RC circuit is now connected to the other RC circuit in series.
01:03:12
By these distances, right. So that's how one would go about modeling more spatially complex neurons.
01:03:19
But. And in fact, if you want to have modeling software for by physically detail and spatially extended neurons there is a software suite called neuron.
01:03:27
And it allows you to put in just scanned images of neurons and their shapes and it will generate for you that equivalent spatially complex
01:03:40
Dendritic models, a professor
user avatar
Brody West
01:03:43
So I'm trying to understand the reasoning behind this.
user avatar
Ila Fiete
01:03:46
Yeah, is
user avatar
Brody West
01:03:48
The intent to have an RC circuit for every sin apps on the dendritic branches.
user avatar
Ila Fiete
01:03:55
Oh, so you could do that in general this model typically settled for less. They said Ofer
01:04:05
Chopping up. Say again right into something like 10 compartments. So like you can see in this example.
01:04:10
Here's the neuron in a B is this cable model. And you can see that this cable model has been
01:04:15
chopped up into 12345 compartments going from the soma, all the way out to the tip of the dead right
01:04:22
And there's many, many snaps is along the length of this. So there would be probably hundreds of synopsis along the length of each of these little compartments. So I wouldn't say that this is the level of a single capacity model per
01:04:34
Snaps but it is a single compartment role model for each stretch of den. Right, and I think
01:04:41
It all depends on, so it's it's a trade off. Right. So the problem is you can always model something with high complexity and detail but but the trade off is that, you know, the more detail and complexity put into the models.
01:04:53
And the less information you have about the detailed parameters to put into each of those into that rich model, then you might be left with less rather than more because you have more details, but less constrained details.
01:05:08
Sure.
user avatar
Brody West
01:05:09
Oh, are you doing this.
user avatar
Ila Fiete
01:05:11
Why would one do this. Okay, so in this class. We're not going to be doing this, um,
01:05:15
There are many important reasons to do this and we'll come back we'll circle back to those. But, um, you can you can treat. So you can see here that one neuron because of its
01:05:25
Spatial extension and the fact that the voltages can differ along the den right means that
01:05:31
We should really define neural activity by a single variable which is voltage of the soma, it should really be a whole set of variables, which is a whole set of voltages
01:05:40
So then you can now start thinking about a single neuron is a network.
01:05:44
Right, so a neuron itself can be a whole network. So if, if we're even coming at this from the perspective of machine learning and artificial intelligence. The question is how much competition happen and single neuron and
01:05:56
So far what I've shown you in this model is these are just linear. These are just RC circuits. Right. So these are all linear models.
01:06:05
There's no non linearity in these dendritic components. But in real neurons. It turns out that there's also a lot of nonlinear processing within single dendritic component. So, if
01:06:15
The voltage in this piece of dead right goes above a certain threshold, only then will they transmit much of a signal to the next segment of the den right and so on.
01:06:24
So once you add a nonlinear elements to these different dendritic compartments. Then you suddenly open the door to each neuron being a whole neural network, rather than each neuron being one neuron in your own
user avatar
Brody West
01:06:37
Does that answer your question.
01:06:39
Yeah, I think, if I understand it correctly, um, this factors in the
01:06:48
The limit. The limit of
01:06:52
Ability for like a
01:06:56
Like an action non action potential to any kind of substantial change to distribute spatially through the dendritic branches. Right.
user avatar
Ila Fiete
01:07:04
That's right. That's right. So in the past have done right model, which is like no active know nonlinear processes in the den right just RC circuits.
01:07:11
If you make a small change in the voltage at the tip of the den right then it will take. First of all, a long time to propagate through this and right but also it will be dissipated.
01:07:19
It will be
user avatar
Brody West
01:07:20
It will be business model doesn't concern climate differences. Right. It's just a matter of spatial differences.
user avatar
Ila Fiete
01:07:27
So that's what this model also will have time built in right because it's it's a bunch of RC coupled am a circuit. So there will be some temporal change right you can describe
01:07:39
Us. Right. So there will be temporal dynamics in this model already. Yeah. So it's a spatial temporal model.
01:07:46
Yeah, because, because the voltage is described by temporal equation right it
01:07:50
Is the differential equation. So this tells you how if you make an instantaneous change and I, it'll still take some time for that to be reflected in the voltage and so each compartment will do this temporal filtering through the capacitive memory capacity. Right.
01:08:04
Okay, so, um, so. Okay, so here we are, then. So now what are these components. So, so in other words, what I'm saying is, I've given
01:08:12
You this this view of a more complex neuron.
01:08:15
And told you that there are ways to model it and but we're not actually going to go there. So we're not really going to model the neurons.
01:08:22
In the specialty temporally extended way we're going to treat them as the simple objects that are just a sack or a ball or spiritual neuron, as we like to say in physics.
01:08:30
So we're making a spherical neuron approximation and just treating the voltage in the neuron at ISO potential. So each in Iran has a single variable attached to it, which is a voltage and
01:08:40
Okay, so see some and refers to the membrane capacitance of the neuron G. Some M is the membrane conductance. This is the conducted says that the cell
01:08:50
Users to pump out i i on. So this is, I got on a conductance is that are keeping the cell at rest. Here's the best resting battery and this resting resting battery that I told you about is about Senate minus 55 minus 16 million volts across neurons.
01:09:08
So, okay. So assuming that is small, or zero, then, then the cell is maintained below this action potential threshold and this equation is actually a pretty accurate.
01:09:20
Representation of the dynamics of neurons even recording neurons below action potential. So just some numbers here. So membrane capacitance of a cell a cortical neuron is typically one micro Farid per centimeter squared.
01:09:34
The inverse conductance of the resistance of the cell membrane is is is is 10,000
01:09:41
On centimeter squared. So it's pretty resistive. And so then, these two are constants which are the capacitance and the conductance across the membrane.
01:09:50
Give you an effective time constant which is Tao, which is Sierra GM and that is about 10 milliseconds. So this is that capacitive membrane time constant. I was telling you about. And that's what sets the
01:10:01
Time scale. So just take note of the short single neuron time constant which is equates to sort of the memory of a cell of its of its activity level right so the activity. A cell remembers its activity level for about 10 milliseconds before going back to its resting activity level.
01:10:22
Okay, so, um, now. Okay, so if I have zero or if i is small, such that the cell doesn't come up to the threshold voltage for generating an action potential, then
01:10:36
We can solve for for fixed current we can solve for the steady state voltage of the of the cell. So to solve for steady state voltage anybody. How do we solve for the steady state voltage
user avatar
Bhav Jain
01:10:48
You, you simply set dV over dt to zero because it's unchanging.
user avatar
Ila Fiete
01:10:53
That's right.
01:10:53
So you just set the time derivative to zero because we're assuming it's on changing. And then we solve for me.
01:10:58
So if the left hand side is zero, then we just get that v is equal to I applied for Reggie membrane. Plus, remember
01:11:06
Okay, so, so in other words the resting wilted have a cell that the given applied current is just the the resting membrane of the cell, without any applied currents, plus an increment because of the applied current normalized by the membrane conductance.
01:11:22
Okay, so, so if you give a deep polarizing current injection, but keep it sustain sustain that input.
01:11:30
Then the cell will just
01:11:32
Have a membrane potential that is proportional it's changed from its resting value proportional to that applied current of the pie current is negative, the voltage becomes more negative if the current is positive, the voltage is the polarized.
01:11:48
Okay. So I'm now a quick note on numerical integration and this is something we'll go over in the tutorial. So if you've got a differential equation, like a first
01:11:55
Order non linear differential equation.
01:11:58
In a single variable here which looks like dx di t equals f of x comma t or f is some nonlinear function of x, then you can
01:12:10
Numerically integrate this equation. So if this is analytically solvable, then you would try to integrate this analytically, but if it's not analytically solvable. You can numerically integrate this equation to estimate the next
01:12:23
Value of X given a previous value of x. So the way you do this as you replace the time derivative
01:12:29
By finite difference approximation of the time derivative. So we just take dx dt and replace it by x A t plus delta t minus x 50 and then divided by delta t.
01:12:41
On the left side. So in other words, it's just the derivative without taking the limit of delta t point zero
01:12:47
Okay. And then on the right side, we just have f of x committee and then we simply solve for x 50 plus dT.
01:12:54
Plus delta t. So, which is the previous value of x plus an increment given by this nonlinear function f. Okay. And this is, this is called an Euler.
01:13:05
Integration for a numerical Euler update for differ a differential equation and this
01:13:12
Equation is reasonably accurate in the limit of it's accurate in the limit of delta t going to zero. And it's, you know, fairly accurate for small on delta t, but of course what delta t should be depends on
01:13:26
Depends on the problem and the non linearity, etc. So, so here so it takes a single value across one more time, been so it's taking this continuously time varying
01:13:39
quantity X of tea here which is continuously very in time and replacing it with an ex of tea that has a single value over a whole time in. So in other words, we're replacing x 50 the continuous X 50 by it's time average
01:13:54
Of the continuously varying activity over that one been so that's how we should think about this discrete time X of tea as the time average over one been of the smooth leverage activity.
01:14:07
Okay, so, um, alright. So, so in this class, mostly will be dealing only with numerical integration, a first order differential equations with no delay.
01:14:16
So if it's no delay then given x zero, you can then iterate that numerical equation to obtain all the subsequent expertise to give an exit zero, you can get x one x one x two and so on.
01:14:26
No other methods, very simple, but it's slow because you have to choose a sufficiently small DT to get reasonable accuracy and how small
01:14:33
You should choose it depends on the dynamics right detail problem. And there are much more efficient method for a match the accuracy. So to achieve the same level of accuracy as the lawyer method.
01:14:44
You can do that with with higher efficiency using other methods higher order methods like Ranger kinda adaptive step size, etc. But again, for this class, you are probably safe using disorder method, unless you just want to use something fancier
01:14:59
Okay, so if we want to now integrate we so let's do that. So let's numerically integrate the sub threshold voltage of a cell. So we take this equation over here and I just
01:15:12
plot it. So this is time over here. This is voltage and this is the membrane potential of the cell sitting at minus 55 million volts, because my m is minus 55
01:15:24
So when I applied to zero, then this is just constant
01:15:28
When I applied is a current step that goes on at time t equals zero and goes off at time 750 milliseconds, then the response of the membrane voltage is this orange curve here it ramps on and then ramps off.
01:15:43
And similarly, if the end this time constant of decay here is given by this capacitive time constant Tom membrane. So this is your single exponential decay time constant of about 10 milliseconds.
01:15:57
So now this describes the the sub threshold dynamics of voltage in a neuron. So now,
01:16:07
That's boring because the cells are sitting there and it's not doing anything interesting. So, um, how does one build in action potential generation and dynamics. So first,
01:16:18
The Hodgkin Huxley model for action generation. So remember Hodgkin hopefully are the guys who measured
01:16:24
The action potential and squid giant axon. And then they built the first mathematical models that quantitatively described the shape of the action potential. And it's initiation so
01:16:35
So how do we modify the model we've seen before, to include spiking dynamics. So what we do is we add another set of currents which are called ice spiking. So these are spiking currents
01:16:47
And now these spiking currents our current. The depend nonlinear Lee on the voltage of the cell itself. So these currents tend to be zero.
01:16:57
When the cell is close to testing voltage so envious close to VM, then these currents are zero.
01:17:05
When we approaches we threshold some threshold for spike initiation. That's when these spiking currents become substantially non zero and these highly nonlinear dependency is what leads to this very
01:17:20
Rigid, this, this, this, this stereotyped nonlinear action potential shape that we saw earlier. Okay, so in other words all one has to do is
01:17:29
modify the existing capacity of equations with just a special set of currents okay to generate on the Hodgkin hopefully equations that describe realistic spiking dynamics ignorance.
01:17:41
So the way that you can actually did this is that they built in another set of
01:17:46
Occurrence here are modeled by variable conductance, as in Excel. So these are conducted says now these are resistors and conducting says that our functions of the cells voltage over here. So,
01:17:58
So, so these are different currents that have that are driven by different potentials different batteries and because the conductance is voltage gated
01:18:08
This is the control that allows synaptic currents to be spiking currents to be close to zero at negative voltages and then only kick in at higher voltages
user avatar
Tho Tran
01:18:20
I think some people have to go
user avatar
Ila Fiete
01:18:22
Oh yeah, I'm sorry. I have lost track of. Okay, yes indeed thank oh
user avatar
Tho Tran
01:18:34
We cannot hear you. Can you
user avatar
Ila Fiete
01:18:44
I'm so sorry I did not look at the time because it was hidden behind my participant bar.
01:18:49
So, I'm sorry, I will let you guys go I was running further behind than I thought I was so
01:18:55
Okay, so let me just, just say one thing before I let you go. So right now you have
01:19:00
enough information to do some of your homework. I guess I just want to describe one thing which you can now read, I will post the slides. You can read them.
01:19:08
And it's about a simple model for action potential generation, which is just a threshold mechanism that just pretend a spike occurred and then resets the potential back to
01:19:18
Resting value. So that's described in the homework. So you have enough to do the homework and we will cover the rest afterwards. But I'll make these slides available now. Sorry for running over
01:19:31
By bye
user avatar
Minyoung Kim
01:19:33
Thank you.
01:19:33
Thank you.
user avatar
Chi-Ning Chou
01:19:35
Thank you.
user avatar
Ila Fiete
01:19:36
Thanks. Bye.
user avatar
Annika L Heuser
01:19:37
Thanks. Bye.
01:19:41
I'll be stepping
user avatar
Ila Fiete
01:19:43
In the next in the other link. Oh.
user avatar
Jiajia Zhao
01:19:47
Where's the other is it on
user avatar
Ila Fiete
01:19:48
The other link is also on the course web page. If you go to calendar, the zoom right
user avatar
Jiajia Zhao
01:19:53
I'll go there.
01:19:54
Yeah. All right, bye. Thank you.